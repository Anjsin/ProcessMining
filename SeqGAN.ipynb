{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173688</td>\n",
       "      <td>[9, 6, 7, 19, 19, 0, 14, 5, 12, 15, 21, 19, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173691</td>\n",
       "      <td>[9, 6, 7, 19, 19, 19, 19, 0, 5, 14, 12, 15, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173694</td>\n",
       "      <td>[9, 6, 7, 19, 19, 19, 19, 19, 19, 19, 19, 0, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173697</td>\n",
       "      <td>[9, 6, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173700</td>\n",
       "      <td>[9, 6, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid                                           sequence\n",
       "0  173688  [9, 6, 7, 19, 19, 0, 14, 5, 12, 15, 21, 19, 21...\n",
       "1  173691  [9, 6, 7, 19, 19, 19, 19, 0, 5, 14, 12, 15, 21...\n",
       "2  173694  [9, 6, 7, 19, 19, 19, 19, 19, 19, 19, 19, 0, 5...\n",
       "3  173697                                          [9, 6, 4]\n",
       "4  173700                                          [9, 6, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"encoded_sequences.csv\")\n",
    "\n",
    "# Ensure that column names are correctly labeled\n",
    "assert 'caseid' in data.columns and 'sequence' in data.columns, \"Columns are not named correctly!\"\n",
    "\n",
    "sequences = [eval(seq) for seq in data['sequence']]\n",
    "\n",
    "# Extract unique event types\n",
    "num_classes = len(set([item for sublist in sequences for item in sublist]))\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Prepare data\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequence_length = max([len(seq) for seq in sequences])\n",
    "X_train = pad_sequences(sequences, maxlen=sequence_length, padding='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define the Generator\n",
    "\n",
    "generator = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=num_classes, output_dim=128, input_length=sequence_length),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(num_classes, activation=\"softmax\"))\n",
    "], name=\"generator\")\n",
    "\n",
    "generator.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define the Discriminator\n",
    "\n",
    "discriminator = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=num_classes, output_dim=128, input_length=sequence_length),\n",
    "    keras.layers.GRU(128, return_sequences=False),  # Only the last state is needed\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "], name=\"discriminator\")\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/409 [==============================] - 33s 79ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"discriminator\" (type Sequential).\n\nInput 0 of layer \"gru_6\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 175, 24, 128)\n\nCall arguments received by layer \"discriminator\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 175, 24), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Anjali\\ProcessMining\\SeqGAN.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Train Generator\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m discriminator\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m adversarial_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mSequential([generator, discriminator])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m adversarial_model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m y_mislabeled \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39mlen\u001b[39m(X_train), \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Anjali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anjali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Anjali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py:235\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    233\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[1;32m--> 235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    237\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m         )\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"discriminator\" (type Sequential).\n\nInput 0 of layer \"gru_6\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 175, 24, 128)\n\nCall arguments received by layer \"discriminator\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 175, 24), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# Cell 6: Adversarial Training Loop\n",
    "\n",
    "for epoch in range(100):  # Adjust the number of epochs as needed.\n",
    "    \n",
    "    # Generate fake sequences\n",
    "    X_fake_logits = generator.predict(X_train)\n",
    "    X_fake = np.argmax(X_fake_logits, axis=-1)  # Convert softmax outputs to discrete event values\n",
    "    \n",
    "    # Train Discriminator\n",
    "    y_real = np.ones((len(X_train), 1))\n",
    "    y_fake = np.zeros((len(X_fake), 1))\n",
    "\n",
    "    X_dis = np.concatenate([X_train, X_fake])\n",
    "    y_dis = np.concatenate([y_real, y_fake])\n",
    "\n",
    "    d_loss = discriminator.train_on_batch(X_dis, y_dis)\n",
    "    \n",
    "    # Train Generator\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    adversarial_model = keras.Sequential([generator, discriminator])\n",
    "    adversarial_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "    y_mislabeled = np.ones((len(X_train), 1))\n",
    "    g_loss = adversarial_model.train_on_batch(X_train, y_mislabeled)\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "\n",
    "    print(f\"Epoch: {epoch}, D Loss: {d_loss}, G Loss: {g_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters play a crucial role in determining the performance of our model.\n",
    "# It's often a good practice to list them at one place for easy tuning.\n",
    "\n",
    "EMBEDDING_DIM = 128  # Size of the embedding for each event\n",
    "HIDDEN_DIM = 128     # Size of the hidden layers in RNNs\n",
    "MAX_SEQUENCE_LENGTH = 50  # Adjust this based on the maximum sequence length in your data\n",
    "BATCH_SIZE = 64      # Batch size for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 128)           3200      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50, 128)           131584    \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 50, 25)           3225      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,009\n",
      "Trainable params: 138,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The Generator is responsible for creating sequences. \n",
    "# We use an LSTM based architecture to capture the temporal dependencies of the process event logs.\n",
    "\n",
    "def build_generator():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=25, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)) \n",
    "    model.add(layers.LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(25, activation=\"softmax\")))\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 128)           3200      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,913\n",
      "Trainable params: 134,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The Discriminator's job is to differentiate between real and generated sequences.\n",
    "# Just like the generator, we use an LSTM based architecture.\n",
    "\n",
    "def build_discriminator():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=25, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "    model.add(layers.LSTM(HIDDEN_DIM))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "205/205 [==============================] - 17s 73ms/step - loss: 0.7666\n",
      "Epoch 2/10\n",
      "205/205 [==============================] - 15s 75ms/step - loss: 0.0656\n",
      "Epoch 3/10\n",
      "205/205 [==============================] - 15s 74ms/step - loss: 0.0083\n",
      "Epoch 4/10\n",
      "205/205 [==============================] - 15s 73ms/step - loss: 0.0030\n",
      "Epoch 5/10\n",
      "205/205 [==============================] - 15s 71ms/step - loss: 0.0016\n",
      "Epoch 6/10\n",
      "205/205 [==============================] - 16s 77ms/step - loss: 0.0010\n",
      "Epoch 7/10\n",
      "205/205 [==============================] - 17s 82ms/step - loss: 7.1434e-04\n",
      "Epoch 8/10\n",
      "205/205 [==============================] - 16s 77ms/step - loss: 5.3421e-04\n",
      "Epoch 9/10\n",
      "205/205 [==============================] - 16s 79ms/step - loss: 4.1546e-04\n",
      "Epoch 10/10\n",
      "205/205 [==============================] - 17s 82ms/step - loss: 3.3003e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244b982c950>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=num_classes, output_dim=128, input_length=sequence_length),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128),\n",
    "    keras.layers.Dense(sequence_length)  # Remove the softmax activation\n",
    "], name=\"generator\")\n",
    "\n",
    "generator.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/409 [==============================] - 7s 16ms/step\n",
      "409/409 [==============================] - 32s 72ms/step - loss: 0.6935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244c0e63990>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We also pre-train the discriminator to help it distinguish between real and fake sequences early on.\n",
    "\n",
    "X_fake = generator.predict(X_train)\n",
    "X_fake = np.argmax(X_fake, axis=-1)  # Convert probabilities to event indices\n",
    "\n",
    "y_real = np.ones((len(X_train), 1))\n",
    "y_fake = np.zeros((len(X_fake), 1))\n",
    "\n",
    "X_dis = np.concatenate([X_train, X_fake])\n",
    "y_dis = np.concatenate([y_real, y_fake])\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "discriminator.fit(X_dis, y_dis, batch_size=BATCH_SIZE, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further steps might include:\n",
    "# - Incorporating domain-specific rules or constraints into the generation process.\n",
    "# - Using a more complex model architecture or newer models like Transformers.\n",
    "# - Implementing techniques like Reinforcement Learning to further guide the generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/409 [==============================] - 7s 16ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential_1\" (type Sequential).\n\nInput 0 of layer \"lstm_1\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 50, 25, 128)\n\nCall arguments received by layer \"sequential_1\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 50, 25), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Anjali\\ProcessMining\\SeqGAN.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Train Generator\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# We will create an adversarial model for this.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m discriminator\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# Freeze the discriminator\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m adversarial_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mSequential([generator, discriminator])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m adversarial_model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anjali/ProcessMining/SeqGAN.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m y_mislabeled \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39mlen\u001b[39m(X_train), \u001b[39m1\u001b[39m))  \u001b[39m# We want the generator to produce sequences that the discriminator thinks are real\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anjali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anjali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Anjali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py:235\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    233\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[1;32m--> 235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    237\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m         )\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n\nInput 0 of layer \"lstm_1\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 50, 25, 128)\n\nCall arguments received by layer \"sequential_1\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 50, 25), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# This is the core of the GAN. \n",
    "# We alternately train the Discriminator to distinguish real sequences from generated ones and the Generator to fool the Discriminator.\n",
    "\n",
    "for epoch in range(100):  # Adjust the number of epochs as needed.\n",
    "    \n",
    "    # Train Discriminator\n",
    "    X_fake = generator.predict(X_train)\n",
    "    X_fake_indices = np.argmax(X_fake, axis=-1)  # Convert probabilities to event indices\n",
    "\n",
    "    y_real = np.ones((len(X_train), 1))\n",
    "    y_fake = np.zeros((len(X_fake_indices), 1))\n",
    "\n",
    "    X_dis = np.concatenate([X_train, X_fake_indices])\n",
    "    y_dis = np.concatenate([y_real, y_fake])\n",
    "\n",
    "    d_loss = discriminator.train_on_batch(X_dis, y_dis)\n",
    "    \n",
    "    # Train Generator\n",
    "    # We will create an adversarial model for this.\n",
    "    discriminator.trainable = False  # Freeze the discriminator\n",
    "\n",
    "    adversarial_model = keras.Sequential([generator, discriminator])\n",
    "    adversarial_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "    y_mislabeled = np.ones((len(X_train), 1))  # We want the generator to produce sequences that the discriminator thinks are real\n",
    "    g_loss = adversarial_model.train_on_batch(X_train, y_mislabeled)\n",
    "    \n",
    "    # Unfreeze the discriminator\n",
    "    discriminator.trainable = True\n",
    "\n",
    "    print(f\"Epoch: {epoch}, D Loss: {d_loss}, G Loss: {g_loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
